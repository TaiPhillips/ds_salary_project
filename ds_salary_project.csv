,Job Title,Salary Estimate,Job Description,Rating,Company Name,Location,Headquarters,Size,Founded,Type of ownership,Industry,Sector,Revenue,Competitors
0,Statistician & Data Analysis Scientist,-1,"Come grow with us!
Company Description: FDH Infrastructure Services is an industry leader in engineering, construction, and field services for critical structures and facilities. Markets served include Wind Energy, telecommunications, heavy civil, power, industrial, commercial, and government. Our continued success is directly linked to the knowledge and experience of our talented staff. FDH is a team-oriented, performance-driven organization, committed to safety, quality, and professional integrity. Our work culture fosters continuous learning and innovation to improve our products, services, and business processes. We work hard for our customers and enjoy having fun together. Come grow with us!
Enjoy Great Benefits: FDH provides a comprehensive benefits package, including healthcare, dental, vision, life and AD&D insurance, disability insurance, and a 401(k) plan with company match. Flexible time-off plans encourage a healthy work/life balance for all employees. Wellness activities are promoted throughout the year.
*FDH is an Equal Opportunity/Affirmative Action employer and will consider all qualified applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.
*VEVRAA Federal Contractor

The primary function / purpose of this position will be to develop robust, predictive statistical models capable of predicting the presence of material degradation and corrosion. Furthermore, a major part of the job includes uncertainty quantification. This requires an individual that is exceptionally strong in statistics and/or mathematics and possesses the technical aptitude to work with engineers from a variety of disciplines. This candidate will be responsible for developing procedures on gathering existing data and / or generating new data to achieve project objectives. They should have experience with the capture of data using different tools, and an extensive knowledge on different data analysis and management methods.
The position will report to the engineering lead and provide detailed information on the results of the research and subsequent meta-analysis. This data may include, likelihood of occurrence of corrosion/degradation modes, uncertainties associated with various testing methods, and rates of degradation/corrosion. The position may require training of other individuals in the development of predictive models and uncertainties quantification.

Master’s or PhD Degree in Statistics or Applied Mathematics required.
Minimum of three years of experience. Experience in engineering or technology related field is a plus.
Proficiency in statistical methods including meta-analysis, density estimation, sample size calculation, inferential statistics, ANOVA, Multivariate Analysis, Linear and Non-linear models, Bayesian data analysis, Mixed effect models, Regression Analysis, neural network and machine learning techniques.
Experience of uncertainty quantification of testing devices, and predictive models.
Proficiency in statistical software like SAS/JMP and R.
Ability to organize and efficiently analyze large sets of research data.
Ability to make meaningful inferences from the statistical results.
Work with the team to manage project task identification and milestone schedule.
Ability to obtain Top Secret clearance required.
Handle multiple projects simultaneously.
Possess the ability to communicate effectively with all levels of management, employees and outside contacts both verbally and in writing.

Action Oriented - is action oriented and works well with challenges., Business Acumen - Knowledgeable in the business, policies, practices and trends., Customer Focus - Establishes and maintains effective relationships with customers., Drive for Results - Pushes self and others for results., Functional Technical Skills - Has functional and technical knowledge and skills.
This position does not have direct reports",3.6,"FDH Infrastructure Services
3.6","Raleigh, NC","Raleigh, NC",201 to 500 employees,1994,Company - Private,Architectural & Engineering Services,Business Services,Unknown / Non-Applicable,-1
1,Data Scientist,-1,"It's fun to work in a company where people truly BELIEVE in what they're doing!

We're committed to bringing passion and customer focus to the business.

Thank you for your interest in NAVEX Global. At this time we are not actively hiring for the Data Scientist role, however, we encourage you to apply and join our Talent Network. We continue to prioritize engaging great people and look forward to learning more about you!

Position Summary:

As a Data Scientist, you will create innovative solutions to solve business problems by using real world solutions for decision making. Designing algorithms that solve business critical problems fo the world’s largest risk and compliance platform, your contributions make a material impact to the business culture. If you want to use cutting-edge machine learning techniques with technoloty that drives crucial decisins, this role is for you.

We Offer You:
An organization that is secure, growing and thriving with a reputation that we are proud to say is absolutely second to none
A workplace experience that is based on our determination to retain you each day and enables you to learn, grow and develop your career, and people dedicated to your success at every level
Competitive pay with benefits that matter, including the time and flexibility to balance the multiple roles you play in life
Access to world’s largest data set in risk and compliance function
What You Will Do:
Analyze large sets of transactional data to understand core domain behavior in the area of Risk and Compliance function
Design, develop, and validate machine learning models, including to deploy, monitor, and maintain models in production.
Statistical modelling
Explore and extract features and patterns to improve model capability
Prototype modeling strategies to train and optimize model performance
Perform link analysis with Users, Cases, Policies and Procedures and Training in an enterprise
Perform time series modeling to predict risk trends
Identify possible problems with data or processes and helps remediate
Extraction, curation and analysis
Data modeling and data transport pipelines to make data available for training and testing models
Drive the determination of technology-driven product features and capabilities
Recommendation on Language and library specification and help establish processes for a growing data science team
What You Will Need:
Background in STEM with 2+ year experience as a data scientist with specialization in machine learning, statistical modeling and optimization
Strong knowledge in predictive modeling, statistics and data science
Experience in machine learning including neural networks, reinforcement learning, adversarial learning, etc.
Desired experience in visualization tools such as ggplot, d3.js and Matplottlib, and Tableau
Proficiency in one or multiple data science programming languages such as R, Python and Spark
Database design and sql queries to extract data
Ability to communicate with both business and technical leaders
Proficiency in collecting and mining data from disparate data sources, and willing to dig deeper and understand the process that creates the data
Ability to prioritize, execute and deliver projects on time
Capability to translate business opportunities into data science problems and define the correct project scope and performance metrics to measure success
Experience working with agile development teams and processes
Experience with change management, process improvement and project management
Ability to build consensus among different groups with competing demands
Experienced planning for the future, keeping abreast of new trends and technologies while managing day-to-day projects
A commitment to do the right things right
NAVEX Global is an equal opportunity employer, including disability/vets.

If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!",3.2,"NAVEX Global
3.2","Lake Oswego, OR","Lake Oswego, OR",1001 to 5000 employees,2012,Company - Private,Computer Hardware & Software,Information Technology,$100 to $500 million (USD),-1
2,Data Engineer,-1,"A Bit about Us

Our organization was founded in 1953 by Louis Spaw and Frank Glass, hence the name SpawGlass. With 10 offices across Texas, the company now has approximately 750 employees statewide and is 100 percent employee-owned with ownership open to all employees. Our DNA is comprised of five core values: Build Trust, Be Professional, Live Teamwork, Be Passionate and Think Like an Owner and our purpose is to provide our clients with the absolute best construction experience.

What Sets Us Apart

We don't just build buildings, we build people, and our core values aren't just stated, they're practiced. We not only want to hire difference makers; we also want to retain them. The average tenure of our team members is 10 years – more than twice the median years of tenure in the construction industry nationwide.

Accountabilities:
Build a growth mindset
Develop and maintain excellent relationships with project team members
Assist with the design and management of the technology stack used for data storage and processing.
Analyze and translate business needs into data deliverables
Design and development of API interfaces with off-site application/software suites.
Creation of dashboards, reports or downstream data feeds from existing applications
Create and manage data models, data flow diagrams, data mappings, and data dictionaries
Develop and manage databases, data pipelines, data warehouses, data marts and data lakes
Identify and reconcile data quality and inconsistency issues
Facilitate data integration and transformation requirements for moving data between applications; ensuring interoperability of applications with database, data warehouse and data mart environments
Work with leadership and information security team to ensure confidentiality, integrity and availability of data and recommending improvements
Minimum Education:

A four year technical degree in computer science, engineering, data science or a related field.

Relevant experience with certifications such as MTA-SQL, MCSA Database Development/DBA/BIDS will also be considered.

Experience Required: 6+ years

IT Technologies Preferred:
Microsoft SQL Server
Microsoft Office Suite
Microsoft SSRS
RDBMS
Knowledge of the following is a plus, but not required:
Programming Languages (.NET, VBA, C#, Python)
Microsoft SSAS
Oracle 9i or later
Microsoft Power BI
NoSQL
Data Management Skills Preferred:

Strong understanding of the following:
Database Administration Principles
T-SQL/PSQL
Data Models/Normalizations
Databases
Data Integration
Data Analytics
Knowledge of the following is a plus:
Cloud Data Architecture
Data Warehouses/Data Marts
ETL/API Integrations
Business Intelligence
Master Data Management
Robotic Process Automation (RPA)
Work Environment:

Corporate office environment

Monday – Friday, 8:00 am – 5:00 pm

SpawGlass is an Equal Opportunity Employer.",4.4,"SpawGlass
4.4","Houston, TX","Houston, TX",501 to 1000 employees,1953,Subsidiary or Business Segment,Construction,"Construction, Repair & Maintenance",$500 million to $1 billion (USD),-1
3,Machine Learning Engineer,-1,"POSITION PURPOSE:
This position is responsible for aiding operational areas of the organization leveraging both internal and external data assets to achieve business insights, gain deeper understanding of member needs, and enhance tactical and strategic decision making.
NATURE AND SCOPE:
Collaborates with data science team to extract analytical, behavioral and predictive data sets and data pipelines from ever increasing data resources. Understands progressive statistical, programmatic, and analytical approaches to business hypotheses as it applies to available data. Aids business owners & data science team in the interpretation of source data and associated business data pipelines. Requires a solid understanding of both the technical and business aspects of Data Science and business analytics. Requires full software development life cycle experience within various analytical architectures, including piloting models, architecting underlying data design, and model operationalization. Models will be deployed using agile methodologies to ensure timely and relevant delivery.
Responsible for the design, development, and maintenance of analytical models that will be placed into operation. Will be required to explore internal and external data sources to identify useful structures within the data that were/are previously unknown to the business. Should have a strong understanding of relational and dimensional modeling to facilitate data wrangling, model operationalization, and exploration of data. Responsible for adhering to corporate data governance policy and controls to ensure the accuracy, timeliness and confidentiality of resources under management. Must be able to work with users from all levels of management in developing and implement operational and strategic analytics. The Machine Learning Engineer’s primary focus will be on operationalization of analytical models.

Be the go-to-person for data pipelines to support operational implementation of Data Science and analytical models.
Engineer each solution with serverless technology when possible, with optimized performance.
Execute analytics solution engineering strategy, requirements, and adapt processes as needed.
Perform DevOps and orchestration around supporting data marts and analytical processes.
Monitor and secure usage of data while tracking analytic product performance.
Advise and collaborate in internal partnerships to deliver accurate, available, and accessible API services.
Ensure all security, documentation, governance, and compliance standards are met.
Manage small reporting layer on top of analytical models to ensure accountability and insight into models’ performance and impact.
Identifies potential concerns based on projections of current trends.

Experience developing business analytical solutions in large or midsize companies.
Must be able to manage multiple tasks simultaneously and react to problems quickly.
Contribute to Credit Union culture by keeping a positive attitude and growing relationships
Understanding of the financial services industry desired.
Experience with dashboard design and delivery desired
Must be able to translate concepts and directions into practical solutions.
Must have development experience with various data management technology; NoSQL; relational database; message broker; multi-dimensional database; and design architecture.
Understand data collection, streaming, preparation, analysis, visualization, modeling, algorithm integration, evaluation, optimization within an implementation context.
Must have advanced SQL abilities, experience with both Oracle and Microsoft desired.
Must have advanced programming experience with Python
Must have experience with Linux.
Experience with Anaconda; RabitMQ; Jupyter Notebook; Tableau desired
EXPERIENCE:
3+ years of experience in designing, developing and implementing Data Science solutions.
EDUCATION:
Bachelor of Science degree in information technology, computer science, statistics, or related business degree with equivalent experience of 3 years.
Master of Science in information technology, computer science, statistics, or related degree.",3.8,"America First Credit Union
3.8","Ogden, UT","Ogden, UT",1001 to 5000 employees,1939,Nonprofit Organization,Investment Banking & Asset Management,Finance,$100 to $500 million (USD),"Zions Bancorporation, Mountain America Credit Union, Goldenwest Credit Union"
4,Data Science Manager,-1,"Thank you for your interest in joining our team! We hire right, train smart, empower our employees to make decisions, and provide ample opportunities for growth and ultimate success.

Zen-Noh Grain Corporation (ZGC) was formed in 1979 to accomplish the goal of establishing a safe and stable supply of U.S. corn, milo, soybeans, and other U.S. food supplies. ZGC constructed a state-of-the-art export elevator located at mile 164 on the Mississippi River, in Convent, Louisiana. The elevator can load or unload, simultaneously, more than 150,000 bushels per hour. To this day, the Convent elevator is considered to be the fastest export elevator in the world and has undergone further upgrades to improve operational efficiency.

Do you have a data science background and are looking to join a stable and innovative organization? If so, this could be the job for YOU!

This job is primarily responsible for the development and management of data science, empowering the business to drive smart decision-making capabilities through data driven and analytical solutions in alignment with company strategy. Responsibilities include, but are not limited to, supporting data governance for critical business data, determining and implementing appropriate tools, technique and methodologies to extract data that produces meaningful results, providing strategic guidance and direction for analytical efforts and in conjunction with senior leadership, help the entire executive team continue to deepen understanding of opportunities in our business, and create strategies and tactics to capture those opportunities, across all departments. Additionally, this may role may manage staff.

In this job, you will:
Identify needs, design, manage and implement big data solutions for the organization.
Develop business/data requirements; business definitions of data; data flows; data mappings and lineage based on ""best practices""; specifications to model and implement data collection, optimization, solution delivery, data analytics and other strategies that optimize statistical efficiency and quality.
Design and launch innovative and complex analytic models, utilizing a blend of contemporary and traditional data mining techniques, which, when applied to both structured and unstructured data sets, drive insights and benefits not otherwise apparent.
Lead data analysis efforts, directing as necessary, other business and/or information analysts across one or more concurrent delivery efforts to understand and assess the availability, quality, and optimal alignment of data to meet business needs across operations and solutions.
Oversee the interpretation of results from multiple sources using a variety of techniques, ranging from simple data aggregation via statistical analysis to complex data mining.
Develop data understanding, narratives, and data flows using methods and tools, to translate for data scientists, engineers, designers, and other product managers to shape and drive solution delivery.
Perform data profiling and assessment to interpret data; analyze results using statistical techniques to provide ongoing informational, descriptive, and diagnostic evaluations and data stories; identify, analyze, and interpret trends/patterns in complex data sets; and work with management to prioritize business and information needs.
Provide analysis to inform the design and delivery of the data and analytics value-oriented outcomes, solutions, platforms, and to provide services to continuously assess and generate insights to continuously improve operations, processes, and solutions.
Enable and support the smooth transition of data and analytics solutions from inception through implementation and operationalization to ensure long term stability and reliability.
Collaborate with other areas that are sourcing data and consuming data to align expectations as part of developing requirements, creating and executing test plans and to effectively support production processing.
Present recommendations on an ongoing basis to management and trading staff as to trends impacting the grain industry and price relationships.
Participate in applicable strategic planning meetings relative to capital investments, annual budgeting, and strategic relationship management.
May oversee staffing activities of data science team (hiring, firing, coaching and developing, mentoring, career succession, performance and corrective actions, etc.).
Other duties as assigned
Here’s what you’ll need to be considered:

Education
Required - Degree in Economics Finance, or related discipline.
Experience
Required – 5 years’ technical work experience in a data science/bid data or related analytical position, including experience coding and building databases.
Preferred –Experience leading/managing a team.
Knowledge, Skills, and Abilities
Technical knowledge of data management, statistics and utilization of statistical packages for analyzing datasets, predictive modeling and visualization techniques.
Expert level knowledge and execution capabilities of common data structures, languages, and tools (e.g. SQL, Python, R, Storm, Kafka, Neo4J).
Expert level knowledge in BI reporting and database management platforms including Tableau, MicroStrategy, Redshift, DynamoDB, Hadoop, PowerBI, or Oracle.
Working knowledge of a range of data management and data science approaches, tools, techniques, and methodologies in data and analytics development management.
Broad understanding of data technologies and their applied usage including enterprise data platforms.
Fluent in second language, including Portuguese, Japanese, Spanish, and/or Chinese.
Effective interpersonal, oral and written communication skills with the ability to interact with all levels of people within and outside the organization.
Expert mathematical, statistical analysis and time series skills.
Expert skills with regression models (linear, logistic, stepwise, multivariate, etc.).
Excellent time management and decision-making skills.
Ability to disseminate significant amounts of data into clear and understandable information to use in business decisions.
Ability to solve problems and validate hypothesis with bias awareness.
Ability to be successful and lead others to be successful in a complex environment with multiple decision makers.
Here’s additional information you need to know:
Travel, minimal for trainings and meetings (may include international travel).
Are you ready to make a meaningful career move & an impact at ZGC? Apply today!

Known in our industry for stability and high ethics, Zen-Noh Grain Corporation offers a stellar benefits package including: an outstanding 401(k) retirement plan with company contributions, medical, prescription drug, dental, vision, life, & disability benefits, flexible spending accounts, paid leave (holidays, vacation, sick), wellness programs, recognition programs, community involvement opportunities, and much more!

Zen-Noh Grain Corporation is an Equal Opportunity Employer. EEO is the Law links in English or Spanish.

The above is intended to describe the general content of and requirements for the performance of this position. It should not be construed as a detailed description of all the work requirements that may be performed in the job.

All Third Party Agencies, Headhunters, and Recruiters

Zen-Noh Grain Corporation and its Subsidiaries only forms contracts with recruiters with whom we have an established relationship and with whom we have in place a signed contract. All contact from third parties must go through our Human Resources Department. Any contact made outside of our Human Resources Department by a third party will cancel any future business relationships between the third party and Zen-Noh Grain Corporation and its Subsidiaries.",3.5,"CGB Enterprises
3.5","New Orleans, LA","Covington, LA",1001 to 5000 employees,1969,Company - Private,Logistics & Supply Chain,Transportation & Logistics,Unknown / Non-Applicable,"Bunge North America, Gavilon, The Andersons"
5,Data Engineer,-1,"ARC is searching for a Data Engineer to join our team! In this role, you will provide software development and product delivery support for data products and product teams. You will be responsible for product delivery data pipelines and the product lifecycle with direction from the Product Owner, the Solution Owner and technical guidance from Solution Architects.
If you are searching for a position where you can lend your technical expertise and experience professional growth, then we want to hear from you.

Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.
Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.
Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.
Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.
Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.

Bachelor’s Degree in Computer Science or related field; or equivalent experience
3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),
3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery
3+ years of experience implementing modern applications using:
Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, Fargate
Implementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patterns
Open source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)
Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment tools
Data warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)
Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQL
BI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)
Understanding of Data Management and Data governance best practices
You Will Also Bring These Professional Skills:
Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels
Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams
Ability to discover and define functional requirements and to transform them into technical requirements and solutions
Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture
Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences
A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market
A strong passion to support peers to help meet timelines on larger projects

Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.
Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.
We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.
By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.
EOE M/F/D/V Females and Minorities Encouraged to Apply",3.9,"Airlines Reporting Corporation
3.9","Arlington, VA","Arlington, VA",201 to 500 employees,1984,Company - Private,Financial Transaction Processing,Finance,$100 to $500 million (USD),-1
6,Data Scientist BSLEF8,-1,"E3/Sentinel’s Homeland Security Enterprise (HSE) division is an integrated organizational entity fostering increased collaboration and synergies across the Homeland domain. HSE combines the skills and talents of over 245 (and growing) E3S employees and subcontractor staff supporting multiple components across DHS, including but not limited to: U.S. Customs and Border Protection (CBP), Transportation Security Administration (TSA), U.S. Immigration and Customs Enforcement (ICE), Federal Emergency Management Agency (FEMA), U.S. Coast Guard (USCG), Science and Technology Directorate (S&T), Countering Weapons of Mass Destruction Office (CWMD), Federal Protective Services (FPS), and the DHS Headquarters Management Directorate. Our team provides rapid, innovative and specialized solutions that enable our HSE clients to success at meeting dynamic mission objectives.

Each day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace. The volume and complexity of both physical and virtual border crossings require the application of “big data” solutions to promote efficient trade and travel. Further, effective “big data” solutions help CBP ensure the movement of people, capital, and products is legal, safe, and secure.
In response to this challenge, E3/Sentinel, as a trusted mission partner of CBP, seeks capable, qualified, and versatile data scientists to help lead the development and delivery of high-quality predictive modelling solutions. Successful applicants will serve as recognized subject matter experts in the application of quantitative methods, machine learning algorithms, and predictive models to address complex national and homeland security challenges. They will help our team to leverage large structured and unstructured datasets to develop and operationalize models, tools, and applications that drive optimized decision making. Project tasks include data collection, mining, data and text analytics, clustering analysis, pattern recognition and extraction, automated classification and categorization, and entity resolution to implement and enhance automated risk assessment. The products we develop provide actionable insight with real and immediate impact on the safety and security of the United States, its citizens, visitors, and economy.

Lead and perform hands-on analysis and modeling involving the creation of intervention hypotheses and experiments, assessment of data needs and available sources, determination of optimal analytical approaches, performance of exploratory data analysis, and feature generation (e.g., identification, derivation, aggregation).
Collaborate with mission stakeholders to define, frame, and scope mission challenges where big data interventions may offer important mitigations and develop robust project plans with key milestones, detailed deliverables, robust work tracking protocols, and risk mitigation strategies.
Demonstrate proficiency in extracting, cleaning, and transforming CBP transactional and mission data associated within an identified problem space to build predictive models as well as develop appropriate supporting documentation.
Leverage expert knowledge of a variety of statistical and machine learning techniques and methods to define and develop programming algorithms; train, evaluate, and deploy predictive analytics models that directly inform mission decisions.
Execute projects including those intended to identify patterns and/or anomalies in large datasets; perform automated text/data classification and categorization as well as entity recognition, resolution and extraction; and named entity matching.
Brief project management, technical design, and outcomes to both technical and non-technical audiences including senior government stakeholders throughout the model development/ project lifecycle through written as well as in-person reporting.

Bachelor’s Degree (required), Master’s or Ph.D. degree (preferred) in operations research, industrial engineering, mathematics, statistics, computer science/engineering, or other related technical fields with equivalent practical experience
Significant experience in developing machine learning models and applying advanced analytics solutions to solve complex business problems.
Proficiency with statistical software packages: SAS, SPSS Modeler, R, WEKA, or equivalent.
Experience with programming languages: R, Python, Scala, Java, SQL, or equivalent.
Experience constructing and executing queries to extract data in support of EDA and model development.
Experience with unsupervised and supervised machine learning techniques and methods.
Experience working with large-scale (e.g., terabyte and petabyte) unstructured and structured data sets and databases.
Experience performing data mining, analysis, and training set construction.
Completed CBP Background Investigation clearance (active or re-instate-able)

Experience with big data technologies (e.g., Hadoop, HIVE, HDFS, HBase, MapReduce, Spark, Kafka, Sqoop).
Proficiency with Unsupervised Machine Learning methods including Cluster Analysis (e.g., K-means, K-nearest Neighbor, Hierarchical, Deep Belief Networks, Principal Component Analysis), Segmentation, etc.
Proficiency with Supervised Machine Learning methods including Decision Trees, Support Vector Machines, Logistic Regression, Random/Rotation Forests, Categorization/Classification, Neural Nets, Bayesian Networks, etc.
Experience with pattern recognition and extraction, automated classification, categorization, and entity resolution (e.g., record linking, named-entity matching, deduplication/ disambiguation).
Experience working in a team and deploying solutions in an iterative or agile/DevOps continuous integration and delivery environment using lifecycle management methods and tools.
Experience with visualization tools and techniques (e.g., Periscope, Business Objects, D3, ggplot, Tableau, SAS Visual Analytics, PowerBI).

E3/Sentinel is an equal opportunity employer and Vietnam Era Veterans Readjustment Assistance Act (VEVRAA) federal contractor. All qualified applicants receive consideration for employment without regard to race, color, religion, gender, national origin, age, sexual orientation, gender identity, protected veteran status, or status as a qualified individual with a disability. E3/Sentinel hires and promotes individuals solely on the basis of their qualifications for the job to be filled.",4.4,"E3 Federal Solutions
4.4","Alexandria, VA","McLean, VA",501 to 1000 employees,2004,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
7,"Medical Lab Scientist,Lab Core, Casual/PRN/Evening hours",-1,"When you work at Children’s, you’re part of a treasured place of healing in the Omaha community—and beyond. Join our team of highly engaged, caring professionals who believe deeply in the organization’s mission—to improve the life of every child. We support equity, diversity and inclusion, and as you apply your skills and expertise to helping children, you too will have opportunities to grow your career. In 2021, we’ll open the new Hubbard Center for Children, tripling our capacity to serve children.

When children are your everything, anything can be…

We are currently searching for a Medical Laboratory Scientist, Lab Core to perform patient laboratory testing, instrument calibration, maintenance troubleshooting, quality control testing, and equipment function verification in the areas of Hematology, Microscopy, Coagulation, Chemistry, Microbiology, Virology and Serology. Reports and interprets laboratory test results. Advises and consults with the Medical Staff, nursing staff, and laboratory staff.

Essential Functions/Competencies

Performs laboratory tests on patient specimens in the areas of Hematology, Chemistry, Microscopy, Coagulation, Microbiology, Virology and Serology to assist in identifying medical disorders and to monitor ongoing patient therapy.
Utilizes LIS for reporting patient results, documenting quality control and distribution of data.
Checks instrument calibration and reagent reactivity by assaying quality control specimens to assure accurate patient test results.
Evaluates results of patient testing, quality control and survey testing, takes appropriate action to prevent compromises in patient care.

Participates throughout the calendar year in proficiency testing.

Performs troubleshooting, function checks and maintenance procedures to keep equipment and instruments in proper working order.

Maintains adequate inventory levels and stocking of supplies and reagents.

Supports new staff in training as necessary.

Prepares specimens to be sent to referral laboratories and reports test results as they are returned.

Consults with physicians, nurses and other healthcare professionals concerning requested services and test results.

Performs the duties of Charge Technologist as stated in the Policies and Procedures Manual when assigned.

Regular attendance at work is an essential function of the job.

Perform physical requirements as described in the Physical Requirements section

SECONDARY FUNCTIONS/COMPETENCIES

Performs other duties as assigned

KNOWLEDGE, SKILLS AND ABILITIES:
Ability to communicate effectively both verbally and in writing.
EDUCATION AND EXPERIENCE:
Bachelor’s degree from an accredited college or university in Medical Laboratory Science or related science, which includes a one-year internship in an approved clinical laboratory required.

CERTIFICATIONS/LICENSURE REQUIREMENTS:

Current and valid Medical Laboratory Scientist (MLS) or equivalent certification with the American Society of Clinical Pathology or other equivalent certifying agency required, within 6 months of hire.

EOE/VETS/DISABLED

Glassdoor Ind123 ~hec CHCareerbuilder",3.7,"Children's Hospital & Medical Center - Omaha
3.7","Omaha, NE","Omaha, NE",1001 to 5000 employees,1948,Nonprofit Organization,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable,"Boys Town, Nebraska Medicine, CHI"
8,Data Scientist,-1,"Company Description

MMIT is growing from the leading drug coverage data business into a comprehensive, integrated market access company serving pharmaceutical manufacturers, health insurers, PBMs and healthcare IT companies. Their suite of applications is designed to manage an ever-changing proprietary set of pharmacy and medical benefit information and to provide a structured view of complex market access information. By embedding their data and SaaS applications across healthcare, they help ensure transparency, consistency and informed prescription decisions across the MMIT Network. They partner with hundreds of payers and pharma manufacturers ensuring that their products continually capture and analyze coverage and restriction criteria for more than 98% covered lives.

Team Overview

The MMIT Product Management Team is charged with developing, growing and maintaining the MMIT product portfolio that smooth access to lifechanging therapies. This entails managing products through all phases of the product lifecycle, from concept to sunset. The product management team embraces a market-backed perspective, champions unmet client needs, and is committed to a highly accountable and collaborative Product Management approach.

Job Description

MMIT is seeking experienced Data Scientists to meaningful contributes to the growth and development of the MMIT product portfolio. Ideal candidates are comfortable working with large, complex data sets to help inform, simplify and actualize key product capabilities. They will have comfort collaborating with various stakeholders and navigating ambiguity with limited direction. They will dedicate themselves to understanding the MMIT product portfolio (both current capabilities and future product roadmaps) and key data dependencies to inform data models, architecture, and new product development.

To succeed in this role, you will apply your skillset to

· Inform, create and/or maintain master data hierarchy, attributes and structure.

· Bridge claims data and coverage data – Refine existing rules and create and continually improve new methods for accurately assigning pharmacy and medical claims volumes to MMIT controller entities

· Apply data science to the creation of short and long form geographic market and controller entity descriptive narratives (NLP / NLG)

· Translate product management strategy into actionable data science deliverables, guiding development of data models, business rules and other advanced analytical capabilities

· Excel at communicating across a broad set of cross-functional stakeholders.

· Work collaboratively with MMIT product and data teams to develop and/or commercialize analytics use cases that may include market access, coverage / lives, and RWE data

· Effectively partner with external organizations including clients and vendors to develop meaning and projectable analytics about trends in market access dynamics across payers, geographies, indications, drugs, etc.

· Identify and evaluate additional data sources that could be integrated in value enhancing ways.

· Build reports, dashboards and/or other analyses as needed and/or as specific initiatives arise.

· Support various commercial or commercialization efforts as needed.

· Take a leading role in developing data science as a discipline across product management, development and data operations.

Qualifications

Relevant Skills and Experiences

· Postgraduate degree or higher involving machine learning, statistics, or computer science

· Experience of statistical / machine learning projects in academia or commercial sector end to end with proven delivery capability including capturing requirements, designing analysis plans, interfacing with clients and report / manuscript writing

· Experience in applying Natural Language Processing and related AI capabilities.

· Experience working with large and complex healthcare datasets, preferably patient-level longitudinal data and experience with studies of treatment effectiveness/outcomes, disease progression, adherence, healthcare utilization, patient journey, sales targeting, prescription/procedure volumes/shares, provider networks and prescribing/treatment patterns, etc

· Strong related programming skills including experience with good coding practices and a thorough understanding of the data science package landscape. Familiarity with Tableau and PowerBI a plus.

· Familiarity with agile software development practices

· Excellent written and spoken communication skills, including ability to present technical concepts to lay audiences, write analysis plans for projects, contribute to proposals / grant applications, pitch ideas effectively and persuasively to clients / internal stakeholders, etc.

· Demonstrated ability to work both collaboratively to solve complex problems and individually to research/advance areas of interest and exploration

· Proven ability to develop meaningful/valuable analytic insights from multiple data sources and support value through commercialization

Preferred candidates may also have

· Experience supporting or launching Data and Analytics or SaaS-based enterprise product

· Experience in managed markets and pharma market access ecosystem

· Experience in the commercial health insurance industry

· Knowledge of payer marketing, drug development lifecycle and drug launch process

Additional Information

All your information will be kept confidential according to EEO guidelines.

Position will be based in Livingston NJ or Yardley PA

(highly qualified remote applicants will be considered)

Travel Requirements:

Approximately <10>",3.9,"MMIT
3.9","Yardley, PA","Yardley, PA",201 to 500 employees,1994,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
9,Data Scientist,-1,"Data Scientist
Affinity Solutions / Marketing Cloud seeks smart, curious, technically savvy candidates to join our cutting-edge data science team. We hire the best and brightest and give them the opportunity to work on industry-leading technologies.
The data sciences team at AFS/Marketing Cloud build models, machine learning algorithms that power all our ad-tech/mar-tech products at scale, develop methodology and tools to precisely and effectively measure market campaign effects, and research in-house and public data sources for consumer spend behavior insights. In this role, you'll have the opportunity to come up with new ideas and solutions that will lead to improvement of our ability to target the right audience, derive insights and provide better measurement methodology for marketing campaigns. You'll access our core data asset and machine learning infrastructure to power your ideas.
Duties and Responsibilities
· Support all clients model building needs, including maintaining and improving current modeling/scoring methodology and processes,
· Provide innovative solutions to customized modeling/scoring/targeting with appropriate ML/statistical tools,
· Provide analytical/statistical support such as marketing test design, projection, campaign measurement, market insights to clients and stakeholders.
· Mine large consumer datasets in the cloud environment to support ad hoc business and statistical analysis,
· Develop and Improve automation capabilities to enable customized delivery of the analytical products to clients,
· Communicate the methodologies and the results to the management, clients and none technical stakeholders.
Basic Qualifications
· Advanced degree in Statistics/Mathematics/Computer Science/Economics or other fields that requires advanced training in data analytics.
· Being able to apply basic statistical/ML concepts and reasoning to address and solve business problems such as targeting, test design, KPI projection and performance measurement.
· Entrepreneurial, highly self-motivated, collaborative, keen attention to detail, willingness and capable learn quickly, and ability to effectively prioritize and execute tasks in a high pressure environment.
· Being flexible to accept different task assignments and able to work on a tight time schedule.
· Excellent command of one or more programming languages; preferably Python, SAS or R
· Familiar with one of the database technologies such as PostgreSQL, MySQL, can write basic SQL queries
· Great communication skills (verbal, written and presentation)
Preferred Qualifications
· Experience or exposure to large consumer and/or demographic data sets.
· Familiarity with data manipulation and cleaning routines and techniques.",3.0,"Affinity Solutions
3.0","New York, NY","New York, NY",51 to 200 employees,1998,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,"Commerce Signals, Cardlytics, Yodlee"
10,Data Scientist,-1,"Job Brief

The ideal candidate will have previous Data Modeling experience. Strong preference will be given to candidates with an actuarial background in the property and casualty insurance space.

Overview

IFG Companies is in search of a Data Scientist to join its growing Predictive Modeling team.

The ideal candidate will have previous Data Modeling experience. Strong preference will be given to candidates with an actuarial background in the property and casualty insurance space.

Responsibilities
Build predictive and/or Machine Learning models in SAS
Research new statistical and mathematical techniques that are suitable and helpful for solving business related problems
Prepare data for modelling and make best/creative use of applicable and available internal or external data
Identifying and integrating new datasets that can be leveraged for modeling efforts
Support related processes around effectively deploying model to business
Effectively communicate results in written, oral and presentation formats to technical and non-technical audiences
Qualifications
Bachelor’s degree in statistics, applied mathematics, or related discipline
3+ years of Data Modeling or similar experience.
Experience with predictive modeling (classification, regression, parameter tuning, optimization criteria, feature selection), preferably with multiple techniques
Experience in model validation techniques, model testing and continuous monitoring of model performance
Experience in Property & Casualty Insurance is strongly preferred.
Demonstrated experience working with large relational data sets.
Working knowledge in SAS, R, Python or another platform to develop and implement predictive models.
Ability and willingness to quickly gain knowledge of SAS enterprise guide and enterprise miner.
Ability to communicate complex technical information in common language to foster teaching and analytics guidance to internal customers.
Advanced experience in analytics, data cleaning, and predictive modeling.
Ability to write queries in SQL.
Detail-oriented and ability to work collaboratively
Physical Demands
Physical demands are considered to be that of an office environment, climate controlled, with minimal physical exertion. This position requires prolonged sitting, ability to utilize a computer and interactions with others in meetings or via phone.
Benefits
We offer a competitive compensation and benefits package including medical, dental, vision, 401(k), flexible spending, short-term and long-term disability insurance, life insurance, long-term care, education assistance and paid time off.
IFG Companies is an equal opportunity employer committed to a diverse workforce. M/F/D/V",2.9,"IFG Companies
2.9","New York, NY","Hartford, CT",201 to 500 employees,1985,Company - Private,Insurance Carriers,Insurance,Unknown / Non-Applicable,"Colony Specialty, Markel, RLI"
11,Senior Data Modeler,-1,"We're looking for an innovative Data Modeler to join our Digital Analytics team. As a Data Modeler, you'll engage with business teams to understand requirements, design conceptual, logical and physical data models, and perform root-cause analysis and recommend solutions. Qualified candidates will have at least 7 years of data modeling background and experience using ERWIN data modeler. Plus, candidates should have previous financial industry experience (bank or credit union) and expert knowledge of relational DBMS, specifically Oracle and Microsoft SQL Server. A strong consultative background with exceptional writing/thought leadership skills will help drive your success.

Here’s what you can expect from the job and what you need to be successful:

Job Duties:
Develop the Enterprise Logical Data Model (LDM) and project Logical and Physical Data Models (PDM), including data warehouse and data mart designs. Facilitates JAD sessions to determine data rules, and holds LDM reviews with peers, data subject matter experts, and development and architecture teams
Partner with internal business partners in understanding and translating business needs into data models, creating logical and physical data models using best practices to ensure high data quality and reduced redundancy of product pnformation
Create and maintain data models, data maps, and system interrelationship diagrams for data domains and systems
Define and govern data modeling and design and naming standards, tools, best practices, related development methodologies and QA data requirements for the organization
Develop solutions and strategies based on the analysis of customer business goals, objectives, needs, and existing infrastructure
principles, concepts and techniques of skills in developing solutions and strategies.
Partner with stakeholders to determine a data strategy and architecture; as well as suggests and implement improvements in architecture, team processes, and functions based on data analysis
Regularly interacts with external customers and customer managers and identifies additional opportunities in customer organization.
Serve as a pre-sales support specialist through the development of materials and by presenting solutions to prospective clients as a subject matter expert
Essential Skills:
Minimum 5 years prior experience as a data analyst and data modeler
Minimum 5 years of experience with ER Studio and ERwin
Minimum 5 years of experience with Logical Design demonstrated with large scale, multiple business solutions across divisions or enterprise
Minimum of 1 year experience in modeling in a Snowflake and Talend solution environment
Strong ability to understand data relationships and can design data models that reflects these relationships and facilitates efficient ingestion, processing and consumption of data
Excellent problem solving and communication skills; experience in interacting with technical and non-technical stakeholders at all levels.
Able to multi-task and manage multiple priorities concurrently
Effective problem-solver, with extraordinary analytical skills and attention to detail
Bachelor’s Degree or equivalent experience
Location: San Jose, CA 95134

First Tech is not currently offering Visa sponsorship for this position",3.4,"First Tech Federal Credit Union
3.4","Rocklin, CA","Hillsboro, OR",1001 to 5000 employees,1952,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
12,Senior Research Statistician- Data Scientist,-1,"Acuity is seeking a Senior Research Statistician- Data Scientist to use statistical knowledge and research skills to solve business problems. The Research Statistician will develop, implement, and interpret statistical models with a strong emphasis on data mining and statistical/predictive modeling. Provides work direction.
ESSENTIAL FUNCTIONS:
Identifies and acquires additional data sources, both internal and external, that can be used to enhance analyses.
Lead the development of analytical models to drive superior business outcomes.
Develop in-depth understanding of drivers for optimization by utilizing statistics and data mining techniques.
Using latest PC tools, develop, enhance and monitor reports and models for other business areas.
Evaluate and use Data Mining Tools.
Support, train, encourage, consult other areas in the company and provide actionable information to management.
Continually monitor database information and future needs.
Explore and acquire data from outside sources.
Use database tools to support other departments
Regular and predictable attendance.
Perform other duties as assigned.
EDUCATION:
Masters/PhD in Statistics, Mathematics, Economics, Operations Research or Computer Science
EXPERIENCE:
5 years P&C insurance, modelling and project leader experience. Programming skills including SAS and R.
OTHER QUALIFICATIONS:
Strong interpersonal, quantitative, problem-solving, computer and conceptual skills.
Aptitude in predictive modeling, multivariate analysis, statistical modeling, data mining techniques and mathematical statistics.
Ability to apply strong programming and data management skills.
Knowledge of and experience with at least one major computer programming language or advanced syntax in a major statistical package.
This job is classified as exempt.",4.8,"Acuity Insurance
4.8","Sheboygan, WI","Sheboygan, WI",1001 to 5000 employees,1925,Company - Private,Insurance Carriers,Insurance,$1 to $2 billion (USD),-1
13,Data Scientist Architect,-1,"This career opportunity is in our Minneapolis office. This individual contributor position will be a member of a high-performing technology team that leads the firm in Business Intelligence and data services by providing architectural guidance, technological vision and solution development. Specifically, this position will be utilizing advanced analytics, data science and machine learning to give our business and our products a competitive advantage. It includes understanding and managing the data, how it interconnects and architecting data for self-serve BI and BA opportunities. This position is for a person that is both business savvy and an expert in data analytics/data science that enjoys framing a problem, shaping & creating solutions and helping to champion implementation.

PRIMARY DUTIES AND RESPONSIBILITIES
Identify and prioritize business use cases. Understand the business, strategy and work with business leaders to identify and prioritize problems that advanced analytics is suited to solve. Effectively communicate these ideas to senior management. In other words, translate business problems into advanced analytics/data science projects and lead in quantifying the various types of risk and rewards that allow these projects to be prioritized.
Stakeholder thought partner to stakeholders by understanding the business needs through a deep knowledge of business operations, the key strategic objectives of our stakeholders, and what stakeholders need to achieve those strategic objectives. Seen by the stakeholder as an extension of their team and brought in for strategic and operational conversations.
Operationalize data and analytic products while also making sure they continue to deliver value. Be able to tell the story of how data and analytics is positively impacting stakeholders. Work closely with the business to achieve real value through informed decisions and improved actions.
Give direction and insight on all data analytics large initiatives/epics/areas of focus.
Build end to end advanced analytics, DSML and AI solutions.
Collect and prepare data. You will help identify the business data needed to produce the most useful insights and future analytics. This would include business line and possible outside sources of data. Ensuring alignment on short-term delivery goals and long-term data and analytic roadmaps with clear articulation of expected value and how the work is to be prioritized.
Validate business implications. You will synthesize analytics-derived insights into easy-to-understand, actionable recommendations that business users can easily understand. Ensure that the insights generated through sophisticated analytics translate to help drive revenue and cost-effective scaling.
Stay abreast of the latest developments and advancements. And how they could impact SullivanCotter.
EDUCATION AND EXPERIENCE REQUIREMENTS
Bachelor’s degree in business, IT, mathematics, statistics or relevant degree program.
10+ years' experience in data analytics or a data scientist or data architect role.
Expertise solution design, problem framing, design thinking, analytics techniques and building solutions.
Skilled at communicating with a variety of methods to include written business cases, data visualizations and infographics.
Demonstrated technical excellence in BI, reporting and analytics tools, analytic solutions (e.g. Power BI, Tableau, R), data visualization, data analytics processing, Python, SQL, AI, and ML.
Experience with the techniques and technologies of data science, along with a comprehensive understanding of the challenges associated with each (e.g. overfitting, model refresh, challenge of acquiring training data, cost of compute, etc.).
Demonstrated communication and influencing skills with business and technical leaders. A talent for boiling complex ideas down to clear, practical choices. Track record of delivering multiple projects with tangible impact.
Extensive experience leading large complex projects, including strategic and tactical planning and implementation, analysis, design, technology selection and deployment.
Results driven–sets aggressive goals and is accountable for continuously driving improved outcomes, leads change, and ensures high standards.
Storytelling: ability to communicate complex ideas in a way that is digestible to broad audience and leads to decision and action.
Track record of developing and implementing innovative highly available, scalable and secure enterprise data and analytic deployments to meet current and future business needs.
BEHAVIORAL ATTRIBUTES
You are passionate about helping organizations drive their success utilizing data.
Skilled storyteller with a passion for data, you will analyze and evaluate data to create innovative advanced analytics to provide the business a competitive edge.
Inquisitive, desire to ask questions and get a deeper understanding of issues (business and data).
Innovative, ability to imagine new analytical solutions to any problem.
Confident, able to challenge perceptions and biases of individuals at every level of the organization in order to enact improvements.
Ability to communicate to both technical and non-technical people. Passion to give others an advantage of understanding by using accessible language.
Business oriented, solid understanding of business requirements and vernacular.
Highly detailed where and when you need to be, able to be less detailed when you need to be.
Curious, stays abreast of current and upcoming technologies and tools.
Applicants for employment must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).

Qualified applicants will be afforded equal employment opportunities without discrimination because of race, creed, color, national origin, sex, age, disability or marital status.

Apply Now",4.2,"SullivanCotter
4.2","Minneapolis, MN","Chicago, IL",201 to 500 employees,1992,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Mercer, Korn Ferry, Integrated Healthcare Strategies"
14,Data Scientist,-1,"The Senior Data Scientist will build and improve analytic pipelines to consolidate multiple data sources, perform analytic processing, and produce actionable business information (e.g., top-10 lists, pattern-matches, exceptions, or lists of 'needles in the haystack'). S/he will apply hands-on development skills and experience as an expert in analytics, data science, pattern recognition, and predictive models. The Senior Data Scientist will build, redevelop/modernize, optimize, and recommend cloud and server-based data science, analytics, and visualization solutions. The Senior Data Scientist may build classifiers, machine learning systems, state-of-the-art data mining methods, and anomaly detection systems.

This project serves the needs of a new agency organization advocating technology capabilities and solutions for counterintelligence and collaborating with operational and support elements throughout the agency. The project helps the agency's enterprise-level initiatives addressing the digital environment. Our team is at the forefront of highly complex, technologically sophisticated IT models and systems serving the nation's counterintelligence needs.

Location: Washington, DC Clearance Required: Top Secret/SCI Travel: None
Status: Full Time FLSA: Exempt
Essential Duties and Responsibilities:
Assist in selecting features, building and optimizing classifiers using machine learning techniques. Document use of classifiers for machine learning techniques,
Help build algorithms to seek out significant information hidden in vast amounts of data by working with users to develop criteria and parameters that effectively highlight and associate areas of interest.
Document algorithms including criteria and parameters used in algorithm, with notes on unsuccessful approaches.
Apply data mining techniques using state-of-the-art methods to find trends and address potential knowledge gaps.
Process, clean, and verify the integrity of data used for analysis and be able to calculate accuracy and/or rank of data in a set in statistical terms.
Create or use automated anomaly detection systems and track system performance highlighting areas for improvement. Document results of anomaly detection and system performance.
Make recommendations on improving existing processes.
Research and develop statistical learning models for data analysis.
Collaborate with various offices and personnel to understand company needs and devise possible solutions.
Communicate results and ideas to unit leadership.
Implement new statistical or other mathematical methodologies as needed for specific models or analysis.
Optimize joint development efforts through appropriate database use and project design.
Create meaningful presentations and analyses which tell a story focused on insights, not solely data.
Synthesize methodology and data into an actionable business strategy and communicate findings to team members.
Your Experience and Knowledge:
Experience with programming languages such as Java/Python/Hadoop
Expert in SQL and other programming languages: RDBMS, MySQL, PostgreSQL, DB2, Informix; proficiency in query languages such as Hive, Pig, etc.
Strong background in data mining and statistical analysis
Understanding and ability to apply machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.

ABOUT POWERTEK

We challenge you to come make your mark. Influence change. Work on vital missions. Advance your career.

Powertek Corporation is a high-energy IT company that encourages its employees to help shape its culture with imagination and ingenuity. Learn more at www.PowertekCorporation.com.

DISTINGUISHING BENEFITS

Matching 401k vested from day one of plan entry

Choice of Health Insurance Plans and an employee assistance program.

Company sponsored technical and management certifications.

PowertekU online education with 4400+ technical and business courses.

Educational tuition reimbursement.

Robust Awards & Recognition Program + perks, discounts, generous referral program.

TO ALL APPLICANTS

Thank you for your interest and effort in applying for this position.

Powertek provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

No unsolicited agency referrals please.",3.7,"Powertek
3.7","Washington, DC","Rockville, MD",51 to 200 employees,2001,Company - Private,IT Services,Information Technology,$25 to $50 million (USD),-1
